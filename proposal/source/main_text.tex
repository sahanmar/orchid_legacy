
% ================================================
\section{Motivation}\label{sec:motication}

Modern Natural Language Processing (NLP) approaches are able to achieve significant results in standard textual analysis tasks. 
The list of tasks includes but is not limited to such fields as text classification, e.g. determining the general topic of the news article \cite{text-classification-Altinel2018} or determining text author's attitude towards the topic \cite{sentiment-analysis-Medhat2014}; sequence tagging,  e.g. named entity recognition (NER)  \cite{ner-Strakova2019,ner-Zhanming2019,ner-Yamada2020,ner-Luoma2020} and part-of-speech tagging \cite{pos-tagging-Bohnet2018}; and text generation \cite{text-gen-Guo2017}. For some applications it is important to combine these tasks to achieve more comprehensible results. 
For instance, in the general case of the sentiment analysis task one aims to classify  whether the author of the piece of text refers to the topic in a negative or positive sense. However, to obtain a finer understanding of why their attitude is inferred to be some particular value, it is important to discern contextual dependencies within the piece, especially in cases when the range of output values goes beyond “polarity” (positive/neutral/negative) and matures into a broader spectrum of values like doubt, contempt, or enjoyment. 
The NLP research community not only actively develops models for improved natural language understanding, i.e. representing language in a vector space, \cite{gpt-Radford2018,bert-Devlin2019,xlnet-Yang2020} but also proposes different fine-tuning approaches for these models \cite{robarta-Liu2019,cr-Joshi2019,gpt2-Radford2019,gpt3-Brown2020}. 

In this project we aim to perform research in construction of better textual dependencies for the task in the form of improved Coreference Resolution (CR). 
The CR task is very complex to solve and from 2019 to this date \cite{cr-Joshi2019} no improvement was achieved on the standard benchmark \cite{ontonotes5-Weischedel2013}. 
The recent article \cite{cr-Toshniwal2020} achieved the same metrics as the one from 2019. 
The CR task is a top-level task for contextual understanding. Thus, the output F1 score of the state-of-the-art approaches show 79.6\%, which is not good enough for the real world application tasks. Hence, the range of possibilities for new solutions is far enough from both exhausting and reaching the saturation point of the research.
 
Coreference resolution combines detection and linking of various mentions of entities within the text: linking noun phrases with their counterparts and pronouns, anaphora disambiguation, linking words with their pro-forms, etc.  
These models have a significant impact on the quality of the text mining algorithms. 
A good use case where  coreference resolution can be applied is categorization of entities and their pronouns in order to provide one with a wider spectrum of information for future decision making. Based on the extracted data it is possible to unify all knowledge in a form of a Knowledge Graph (KG) \cite{kg-Wang2017} which can be further utilized for linking concepts represented by textual spans. The dependencies and connections between the entities can be used for enriching the feature space with the highly discriminative samples for the further tasks. 
The dependencies and connections between the entities can be used for enriching the feature space with the highly discriminative samples for the further tasks. 
For example, let us assume that we have two consecutive sentences like “John Smith and Amanda Brown are accountants in XYZ company. Amanda’s colleague was accused of drunk driving”. Based on these sentences we would like to classify if some of the entities from the text can be charged for a misdemeanor. 
For a human reader it is obvious that Amandas’s colleague refers to John. However for a machine that is a very hard task. However, proper identification of entity clusters like {John Smith, Amanda’s colleague}, {Amanda Brown}, {XYZ} would greatly improve the machine’s understanding of the piece of text.
Another potential application of coreference resolution lies within the problem of opinion mining in media resources where people frequently freely express their views and opinions.
For example, heated discussions may emerge under political news articles. In these discussions, participants refer to subjects of the particular article with, for instance, pronouns. Therefore, proper CR may provide better traction of the audience attitude towards entities from the article by linking comment mentions to them.  


In the scope of this work, we expect to improve the current state of the art (see the following section) by means of its further augmentation. 
Firstly, we believe that advancement can be achieved via the modification of the existing CR-solving model which is applied on top of vector embeddings. 
Since the model relies on scoring entity mentions and clustering them, significant changes can be brought with nonlinear dimensionality reduction which, in neural-network-based structures, can be achieved by means of autoencoders \cite{autoencoders-Zabalza2016,autoencoders-Sahay2019}, since they may enable the model to extract meaningful de-noised relationships from the high-dimensional structure. 
In addition to that, initial tests show that advancements from the named entity recognition field may also provide us with meaningful results, as NER models also focus on entities and context surrounding them: in this case we propose to explore conditional random fields (CRF) \cite{ner-Strakova2019,ner-Zhanming2019,ner-Zhanming2019} and attention \cite{ner-Yamada2020} as potential candidates, as CRF is capable of improving relationship-decoding capabilities of the model and attention learns to put stress on important parts of textual sequences. 
In addition to that, we wish to entertain the possibility of integration of uncertainty representations algorithms \cite{lakshminarayanan2016simple, gal2017deep,welling2011bayesian}. 
The model uncertainty measurement and its representation is done through the empirical estimate and sampling from the model weights distribution. 
The uncertainty representation approach provides the model with the expanded vision of both model learning and inference. 
The described technique has shown that such algorithms may enhance the learning process significantly \cite{ovadia2019can}.

As another output of this project we expect to not only push the boundaries of the state-of-the-art algorithms but also introduce the first Czech and Slovak Coreference Resolution dataset that can be used as a new benchmark for the Czech and Slovak CR models evaluation. Based on the new data and better Coreference Resolution approach  we would like to generalize the CR algorithm as a Multilingual solutiwon.


% ================================================
\section{State of the Art}\label{sec:sota}

Modern Coreference Resolution (CR) algorithms are combinations of sophisticated vector embeddings representing context and deep neural network superstructures that perform the coreference resolution itself. 

Natural language understanding (NLU) models. 
The set of existing models for NLU is vast. 
Arguably, one of the most prominent points in history of such models is when the continuous bag-of-words and skip-gram approaches were introduced \cite{w2v-Mikolov2013}. 
At that point machines started to be able to learn the context surrounding particular words and their vector representations  acquired the ability to represent this context, meaning proximity of such vectors in terms of a metric of choice (L2, cosine/angular similarity) veritably described similarity of words or contexts. 
Still, models of these types were far from perfect, as they provided one with constant vectors per word for a pre-set vocabulary. 
Context-dependent representations with flexible vocabularies became available thanks to the introduction of the Transformer architecture \cite{transformer-Vaswani2017} applied on the vocabulary formed not only by words but also by character n-grams constructed as meaningful parts of words.  
The power of the Transformer architecture lies in its encoding and decoding capability improved by the self-attention mechanism which learns to put stress on parts of text sequences. 
This gave birth to a lot of transformer-based language models such as the Bidirectional Encoder Representations from Transformers (BERT) \cite{bert-Devlin2019}, its fine-tuned variations \cite{albert-Lan2020,robarta-Liu2019} and further models \cite{gpt-Radford2018,use-Cer2018}. 
To this date, SpanBERT \cite{cr-Joshi2019} has proven to be the most efficient architecture for coreference resolution. 
Its crucial difference from the standard BERT model is that it learns to predict the content of masked spans of text, taking into account their beginnings and endings, omitting the ability of the base BERT model to predict foregoing  sentences, whereas BERT learns to predict the following sentence for each preceding one and attempts to infer individual masked tokens. 

The first end-to-end coreference resolution model was introduced in \cite{cr-Lee17}. Its crucial difference from its predecessors was that it did not require preprocessing in the form of syntactic parsing or rule-based mention detection, since the model is able to learn mention dependencies on its own to a forerunner-outperforming extent. 
The main idea of the model is to learn to score pairs of textual spans in such a way that takes into account, firstly, if these spans are entity mentions and, secondly, whether the pair is of type antecedent-descendant in terms of coreference.
Span representations are provided by the NLU model of choice. 
The goal is to be able to assign to each span an antecedent span. The current state-of-the-art approach \cite{cr-Joshi2019} utilizes the same structure on top of SpanBERT. One of the crucial drawbacks of the scoring approach is the choice of spans: sizes of relevant spans can be different so a constant width of the window may not always be the right choice; spans can either overlap or be disjoint; if they overlap, the value of how large the overlap is also becomes a hyperparameter. In addition to that, the number of scoring procedures is quadratic in complexity: each span has to be scored against every its counterpart. If the length of the document is large, the memory needed to store all entity mentions may become an issue (in \cite{cr-Xia2020} authors propose an incremental structure for the CR model which needs a lot less memory for the price of a slight decrease in performance).

The CR scoring model takes as input sequences of high-dimensional word-vectors which were produced by multiple consecutive nonlinear mappings. For that reason, one can assume the resulting language-representing structure is highly nonlinear and noisy. 
In such cases, nonlinear dimensionality reduction helps to preserve crucial information, e.g. probability distribution \cite{dr-VanderMaaten2014} or structure of neighborhood-based local metric spaces \cite{dr-McInnes2018}, while reducing the dimension and noisiness of the space. 
Therefore, by learning vector representations with more informative dimensions with, for example, such neural structures as autoencoders \cite{autoencoders-Zabalza2016,autoencoders-Sahay2019} can lead to improved cluster mention classification results. 
In addition to that, the sequential nature of text and the need to classify relations between entity mentions puts CR close to the field of NER where, for instance, CRF \cite{ner-Strakova2019,ner-Zhanming2019} and attention \cite{ner-Yamada2020,translation-Bahdanau2014} have proven to be good additions  to the sequence-labeling model in the endeavor to learn correct token labels, which is a problem with combinatorial complexity: CRF is capable of decoding of sequential relationships into meaningful labels, which in case of CR may represent relationships between mention spans, whereas attention is able to lay emphasis on trigger words or spans that are essential for the task of question.

Another way to improve the model performance from a different aspect is the addition of the uncertainty measurement. 
The grand research from Google \cite{ovadia2019can} shows that the point wise estimate of model’s parameters does not usually result in an optimal approach. The models uncertainty measurement through the estimate of the empirical model weights distribution has already shown great results in the active learning fields both in Computer Vision \cite{gal2017deep} and NLP in such tasks like NER \cite{shen2017deep, lowell2018practical}, text classification \cite{an2018deep} and other applications. 
Thus, the model parameters estimated based on uncertainty algorithms: i) deep ensembles \cite{lakshminarayanan2016simple} consisting of $N$ networks trained in parallel from different initial conditions; ii) MC Dropout \cite{gal2017deep} which is an extension of the ordinary dropout that samples binary mask multiplying output of a layer, hence stopping propagation through all neurons where zeros is sampled through the network, the extension applies the sampled mask even for predictions generating samples from the predictive distribution; iii) Stochastic Gradient with Langevin Dynamics (SGLD) \cite{welling2011bayesian} which adds additional noise to the gradient in stochastic gradient descent, will bring more efficient training and predictions. 
Back in 2017, the deep ensembles approach for a CR problem \cite{cr-Lee17} showed a significant increase (3\% F1) in the output metrics which confirms the veracity of the concept.

We aim to utilize the knowledge of these aforementioned fields and adapt it to the CR problem to improve the existing framework.

% ================================================
\section{Work Packages}\label{sec:wp}

\subsection*{WP1: State-of-the-Art Models Optimization and Fine-tuning}

\begin{description}
	\item [T1.1] Further enhancement of the state-of-the-art models in PyTorch (\textit{Marko Sahan}) and TensorFlow 2 (\textit{Vladislav Belov}) to support cluster computation optimization and generalization for various text representation mechanisms.
	\item [T1.2] Creation of an environment which is capable of assessing and analyzing the quality of the resulting models in a meaningful and comparable way. (\textit{Vladislav Belov, Marko Sahan})

\end{description}


\subsection*{WP2: Active-Learning-powered Multilingual Data Corpora Creation}

 The datasets used for coreference resolution are very limited. The most well known dataset that is used for coreference resolution is OntoNotes 5 \cite{ontonotes5-Weischedel2013} and it is only available in English, Chinese and Arabic languages. Thus, another objective of the research is the creation of Czech and Slovak datasets.

We would like to introduce the Active Learning data corpuses creation. The experiment is based on the “smart” way of the data collection when the uncertainty based algorithm will choose the unlabeled data by itself and transfer the instances to the annotators for obtaining the labels. 

\begin{description}
	\item [T2.1] Prepare the active learning data collection and labeling environment.
Modern approach of the data collection is based on the random selection of the documents that may meet some criteria like duplicates removal, etc.. The data for the Czech and Slovak corpus are going to be extracted from online news media and czech wiki servers. Recent approaches showed that it is possible to select the data iteratively with the help of the uncertainty based model feedback \cite{gal2017deep, lowell2018practical}. The following approach brings the higher quality data selection that also results in less labeling iterations and lower financial expenses. (\textit{Marko Sahan, Vladislav Belov})
	\item [T2.2] Creation of Czech and Slovak Data Corpuses. The annotations are going to run in the prepared environment from the previous task. In order to reduce the amount of human efforts we will bootstrap the data for the annotations. The bootstrapping approach is based on pre-labeling the Czech and Slovak data with the usage of existing superstructure CR model that uses language independent embeddings for Czech and Slovak language encodings. Described approach will let the annotators to get on average, only task relevant data.
In the first iteration, the target estimate is to have at least 30k-50k annotated sentences for the Czech language. In the second iteration Slovak language data corpus will be collected. The target estimate regarding the annotations is the same as for Czech language (30k-50k). Marko Sahan has the experience of partially leading the end to end 20k sentences corporate corpus creation with entity-to-entity information link labels.  (\textit{Marko Sahan, Vladislav Belov})
	\item [T2.3] Creation of Multilingual validation Data Corpuses. 
Modern algorithms have a clear traction towards the language independent approaches like LASER \cite{artetxe2019massively}. Thus, the generalization of a coreference task is obvious. Language independent embeddings approach is a representation of the same semantic structures with the same, or at least similar (with respect to a specific metric) vectors. Hence, models trained in English must be able to work with different languages. However, in practice, if the model is not fine tuned with another language that it makes predictions for, the error rate of the predicted instances will be higher (this is the reason for T2.1). Nevertheless, modern state of the art approaches were not tested or evaluated on the multilingual datasets either due to the lack of the quality data or due to the fact that the CR field is relatively young. We expect to create 2k testing data corpuses for French, German, Spanish and Turkish. (\textit{Marko Sahan, Vladislav Belov})
\end{description}


\subsection*{WP3: Multilingual Coreference Resolution Model}

WP3 T3.3 and T3.4  are strongly dependent on WP1 and WP2. However WP3 T3.1 can be done in parallel with the WP2 annotation procedure.

\begin{description}
	\item [T3.1] Investigation of influence of (nonlinear) dimensionality reduction on mention clusters in an attempt to reduce the number of noisy dimensions and improve shapes of these clusters. We will experiment with autoencoders \cite{autoencoders-Zabalza2016,autoencoders-Sahay2019} to achieve a nonlinear mapping of the language-representing manifold onto a lower-dimensional de-noised space within a neural-network model. Moreover, since the models for named entity recognition (NER) also work with entity mentions, examination of superstructures designed for NER, e.g. Conditional Random Fields (CRF) \cite{ner-Strakova2019,ner-Zhanming2019} and entity-aware attention \cite{ner-Yamada2020}, applied on the coreference resolution problem will be further explored. (\textit{Vladislav Belov})
	\item [T3.2] Integration of the uncertainty representations algorithms e.g deep ensembles \cite{lakshminarayanan2016simple}, MC Dropout \cite{gal2017deep} or SGLD \cite{welling2011bayesian} to the coreference resolution supertstructure for the empirical model weights distribution estimate. The beforehand mentioned integration will result in more efficient learning and inference. The subsequent step is the improvement and adjustment of the model uncertainty representation algorithms specifically for the CR task. The most naive approach of the ensembles model integration to a coreference resolution superstructure \cite{cr-Lee17} resulted in (3\% F1) increase. Thus, we expect that more sophisticated and adjusted CR problem uncertainty representation algorithms will result in higher and more precise model performance. (\textit{Marko Sahan})
	\item [T3.3] Generalization to multilingual CR superstructure via usage of multilingual NLU models will allow us to evaluate (retrain and test) the CR superstructure from WP1 on the data from WP2 both for base state-of-the-art models and improved models with potentially a more efficient architecture and the uncertainty representations algorithms. The environment prepared in WP1 will enable us to retrain and to get the results consistently and in faster timelines. (\textit{Vladislav Belov, Marko Sahan})	
	\item  [T3.4] The data from T3.3 will allow us to understand the metric baseline for the Multilingual CR model. In the first step, we expect the results from this step to be sufficient enough for their publication as so far no Deep Learning CR results are available for Czech and Slovak languages. (\textit{Marko Sahan, Vladislav Belov})

\end{description}


% ================================================
\section{Research Team}\label{sec:research_team}
\begin{description}
	\item Ing. Marko Sahan
	\item Ing. Vladislav Belov
\end{description}
